{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cfe44e2-24ee-493e-bc97-ed5dcca6f8aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97031eff-20d6-4d99-b7aa-3622c0dbcff0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../Traffic4cast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e9008b6-094e-4648-943e-e2afd63bb3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/gpfs/space/home/pyvovar/repos/TrafficForecast/notebooks',\n",
       " '/gpfs/space/home/pyvovar/miniconda3/envs/t4c22/lib/python38.zip',\n",
       " '/gpfs/space/home/pyvovar/miniconda3/envs/t4c22/lib/python3.8',\n",
       " '/gpfs/space/home/pyvovar/miniconda3/envs/t4c22/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/gpfs/space/home/pyvovar/.local/lib/python3.8/site-packages',\n",
       " '/gpfs/space/home/pyvovar/miniconda3/envs/t4c22/lib/python3.8/site-packages',\n",
       " '../Traffic4cast']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b63e8a-0c5f-4f39-8c42-41b768fb6734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "import tqdm\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import t4c22\n",
    "from t4c22.metric.masked_crossentropy import get_weights_from_class_fractions\n",
    "from t4c22.misc.t4c22_logging import t4c_apply_basic_logging_config\n",
    "from t4c22.t4c22_config import class_fractions\n",
    "from t4c22.t4c22_config import load_basedir\n",
    "from t4c22.dataloading.t4c22_dataset_geometric import T4c22GeometricDataset\n",
    "\n",
    "t4c_apply_basic_logging_config(loglevel=\"DEBUG\")\n",
    "\n",
    "BASEDIR = load_basedir(fn=\"t4c22_config.json\", pkg=t4c22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30d32676-90d5-4740-98ba-0b326a5b16a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd0e617f-bd44-4e96-98c3-cddc422e8cca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f486888-0568-4854-8c05-83f4d90e242c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HIDDEN_CHANNELS = 32\n",
    "NUM_LAYERS = 3\n",
    "NUM_EDGE_CLASSES = 3\n",
    "NUM_FEATURES = 4\n",
    "DROPOUT = 0.0\n",
    "BATCH_SIZE = 2\n",
    "CITY = \"london\"\n",
    "nan_to_num_map = {\"london\": -1.21, \"melbourne\": -0.8, \"madrid\": -0.56}\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4df1618f-61d7-46ef-8118-7c388aaf7187",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/gpfs/space/home/pyvovar/repos/TrafficForecast/data')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASEDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b8fe633-a36f-4987-91ad-70c99a02e0db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RecLinear(nn.Module):\n",
    "    def __init__(self, num_edges, num_nodes, num_attrs, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "\n",
    "        super(RecLinear, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(num_edges, hidden_channels)\n",
    "        self.node_embed = nn.Embedding(num_nodes, hidden_channels)\n",
    "        self.node_embed1 = nn.Embedding(num_nodes, 4)\n",
    "        self.time_embed = nn.Embedding(96, hidden_channels)\n",
    "        self.week_embed = nn.Embedding(7, hidden_channels)\n",
    "        self.node_index = torch.arange(0, num_nodes).to(device)\n",
    "\n",
    "        self.node_lin = nn.Linear(in_channels, hidden_channels)\n",
    "        self.node_lin1 = nn.Linear(hidden_channels * 2, hidden_channels)\n",
    "        self.attr_lin = nn.Linear(num_attrs, hidden_channels)\n",
    "        self.attr_lin1 = nn.Sequential(nn.Linear(num_attrs, hidden_channels), nn.LeakyReLU(),\n",
    "                                       nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels * 6, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.fc1 = nn.Linear(num_nodes, 256)\n",
    "        self.fc2 = nn.Linear(256, 32)  # mean vector\n",
    "        self.fc3 = nn.Linear(256, 32)  # standard deviation vector\n",
    "        self.fc4 = nn.Linear(32, 256)\n",
    "        self.fc5 = nn.Linear(256, num_nodes)\n",
    "\n",
    "        from torch_geometric.nn import GATv2Conv as GCNConv\n",
    "\n",
    "        self.conv1 = torch.nn.ModuleList()\n",
    "        for i in range(3):\n",
    "            self.conv1.append(GCNConv(hidden_channels, hidden_channels, edge_dim=hidden_channels))\n",
    "\n",
    "        self.conv2 = torch.nn.ModuleList()\n",
    "        for i in range(3):\n",
    "            self.conv2.append(GCNConv(hidden_channels, hidden_channels, edge_dim=hidden_channels))\n",
    "\n",
    "        self.gcn_lin1 = nn.Linear(hidden_channels * 2, hidden_channels)\n",
    "        self.gcn_lin2 = nn.Linear(hidden_channels * 2, hidden_channels)\n",
    "\n",
    "    def gelu(self, x):\n",
    "        return 0.5 * x * (1 + F.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "    # coding process\n",
    "    def encode(self, x):\n",
    "        h = self.gelu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "\n",
    "    # Gaussian sampling\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    # decoding process\n",
    "    def decode(self, z):\n",
    "        h = self.gelu(self.fc4(z))\n",
    "        h = self.fc5(h)\n",
    "        return h\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.embed.reset_parameters()\n",
    "        self.node_embed.reset_parameters()\n",
    "        self.node_embed1.reset_parameters()\n",
    "        self.time_embed.reset_parameters()\n",
    "        self.node_lin.reset_parameters()\n",
    "        self.node_lin1.reset_parameters()\n",
    "        self.attr_lin.reset_parameters()\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        self.fc3.reset_parameters()\n",
    "        self.fc4.reset_parameters()\n",
    "        self.fc5.reset_parameters()\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        for lin in self.conv1:\n",
    "            lin.reset_parameters()\n",
    "        for lin in self.conv2:\n",
    "            lin.reset_parameters()\n",
    "        self.gcn_lin1.reset_parameters()\n",
    "        self.gcn_lin2.reset_parameters()\n",
    "\n",
    "    def forward(self, index, edge_index, x, attr, cur_t, cur_w):\n",
    "        mask_idx = (torch.sum(x, dim=1, keepdim=True) != nan_to_num_map[CITY] * 4).type(torch.float)\n",
    "\n",
    "        xmax = 23.91\n",
    "        xmin = nan_to_num_map[CITY]\n",
    "        x_norm = (x - xmin) / (xmax - xmin)\n",
    "\n",
    "        ratio = 0.8 + 0.4 * np.random.rand(1)[0]\n",
    "\n",
    "        x_norm = x_norm * ratio\n",
    "\n",
    "        drop_idx = (torch.rand_like(x_norm[:, 0:1]) > 0.4).type(torch.float)\n",
    "        x_norm = x_norm * drop_idx\n",
    "\n",
    "        x_norm = torch.transpose(x_norm, 0, 1)\n",
    "        mu, log_var = self.encode(x_norm)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_rec = self.decode(z)\n",
    "\n",
    "        x_rec = x_rec / ratio\n",
    "\n",
    "        x_rec = torch.transpose(x_rec, 0, 1)\n",
    "        x_rec = x_rec * (xmax - xmin) + xmin\n",
    "        x_rec1 = mask_idx * x + (1 - mask_idx) * x_rec\n",
    "\n",
    "        attr1 = self.attr_lin(attr)\n",
    "        embed = self.embed(index)\n",
    "\n",
    "        node_embed = self.node_embed(self.node_index)\n",
    "        pre_data = node_embed\n",
    "        for conv in self.conv1:\n",
    "            node_embed = conv(node_embed, edge_index, attr1)\n",
    "            node_embed = self.gelu(node_embed) + pre_data\n",
    "\n",
    "        data = self.gelu(self.node_lin(x_rec1))\n",
    "        pre_data = data\n",
    "        for conv in self.conv2:\n",
    "            data = conv(data, edge_index, attr1)\n",
    "            data = self.gelu(data) + pre_data\n",
    "\n",
    "        x_i = torch.index_select(data, 0, edge_index[0])\n",
    "        x_j = torch.index_select(data, 0, edge_index[1])\n",
    "        x = torch.concat([x_i, x_j], dim=1)\n",
    "        x = self.gcn_lin1(x)\n",
    "\n",
    "        x_i = torch.index_select(node_embed, 0, edge_index[0])\n",
    "        x_j = torch.index_select(node_embed, 0, edge_index[1])\n",
    "        x1 = torch.concat([x_i, x_j], dim=1)\n",
    "        x1 = self.gcn_lin2(x1)\n",
    "\n",
    "        time_embed = self.time_embed(cur_t.long())\n",
    "        week_embed = self.week_embed(cur_w.long())\n",
    "\n",
    "        xf = torch.cat([embed, self.attr_lin1(attr), x, x1, time_embed, week_embed], dim=1)\n",
    "\n",
    "        for lin in self.lins[:-1]:\n",
    "            xf = lin(xf)\n",
    "            xf = self.gelu(xf)\n",
    "\n",
    "        xf = self.lins[-1](xf)\n",
    "\n",
    "        return xf, x_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d49df10-30e0-4841-b224-fb6a5d4f3e23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = T4c22GeometricDataset(root=BASEDIR, city=CITY,\n",
    "    edge_attributes=[\"speed_kph\", \"parsed_maxspeed\", \"length_meters\", \"counter_distance\",\n",
    "        'num_lanes', 'mean_pop', 'catering', 'leisure', 'shopping', 'tourism', 'traffic', 'transport',\n",
    "        'pois_total', 'greeneries', 'water_bodies', 'built_up', 'other', \"importance\", \"highway\", \"oneway\",],\n",
    "    split=\"train\", fill=-1, normalize=\"zs\", cachedir=Path(f\"{BASEDIR}/cache\"), idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3dabc33f-353e-424a-b5ff-a0174692e795",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['root', 'transform', 'pre_transform', 'pre_filter', 'log', '_indices', 'cachedir', 'split', 'fill', 'normalize', 'city', 'limit', 'day_t_filter', 'torch_road_graph_mapping', 'day_t', 'cluster_map', 'edge_index', 'num_importance', 'num_highway', 'num_oneway', 'edge_attr', 'min_volume', 'max_volume', 'mean_volume', 'std'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d516962b-2624-467f-ae41-bb44e8191466",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[59110, 4], y=[132414], volume_class=[132414], median_speed=[132414], max_speed=[132414], t=24, cluster=15, week=3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e3cb634-ce74-41ca-a63e-f854357ae8b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7040"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fd154622-2c8f-46ea-a38f-98354cb82d51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[59110, 4], y=[132414], volume_class=[132414], median_speed=[132414], max_speed=[132414], t=87, cluster=15, week=2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "275ed807-1874-4330-8d6b-93f28046a0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([132414, 37])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "827188f4-a143-4a9d-ba78-626834b19c8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = T4c22GeometricDataset(root=BASEDIR, city=CITY,\n",
    "                                     edge_attributes=[\"speed_kph\", \"parsed_maxspeed\", \"length_meters\",\n",
    "                                                      \"counter_distance\", \"importance\", \"highway\", \"oneway\", ],\n",
    "                                     split=\"test\", fill=-1,\n",
    "                                     normalize=\"sz\", cachedir=Path(f\"{BASEDIR}/cache\"), idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82b919c0-e89d-4ea7-8f2f-3e83b4f9b519",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size\t 7040\n",
      "Test Dataset Size\t 100\n",
      "The statistics of training set are: Min [0]\tMax [7262]\tMean [348.2630]\tStd[289.1282]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Size\\t\", len(dataset))\n",
    "print(\"Test Dataset Size\\t\", len(test_dataset))\n",
    "print(\"The statistics of training set are: Min [%d]\\tMax [%d]\\tMean [%.4f]\\tStd[%.4f]\" % (\n",
    "    dataset.min_volume, dataset.max_volume, dataset.mean_volume, dataset.std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61ccd6ee-217b-4ef6-8520-ab9d35da62e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Size\t 5632\n",
      "Validation Dataset Size\t 1408\n"
     ]
    }
   ],
   "source": [
    "spl = int(((0.8 * len(dataset)) // 2) * 2)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [spl, len(dataset) - spl])\n",
    "print(\"Train Dataset Size\\t\", len(train_dataset))\n",
    "print(\"Validation Dataset Size\\t\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "066f341a-02d9-410e-a8e0-02b1acec9f91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T4c22GeometricDataset(7040)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ddc2664-7ba4-47c1-a8fa-2537dae4ff56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[59110, 4], y=[132414], volume_class=[132414], median_speed=[132414], max_speed=[132414], t=82, cluster=14, week=4)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67c99c93-4977-4b13-9e17-3f6e89b4e11a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[59110, 4], y=[132414], volume_class=[132414], median_speed=[132414], max_speed=[132414], t=82, cluster=14, week=4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7fe01c5f-0b77-404b-9667-4fa77dcb1651",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City Class Weight\t tensor([0.6210, 0.9486, 2.9807])\n"
     ]
    }
   ],
   "source": [
    "city_class_fractions = class_fractions[CITY]\n",
    "city_class_weights = torch.tensor(\n",
    "    get_weights_from_class_fractions(\n",
    "        [city_class_fractions['green'], city_class_fractions['yellow'],\n",
    "         city_class_fractions['red']])).float()\n",
    "print(\"City Class Weight\\t\", city_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2b754cd6-852c-4984-941a-10931492c226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "city_class_weights = city_class_weights.to(device)\n",
    "edge_index = dataset.edge_index.to(device)\n",
    "edge_attr = dataset.edge_attr.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef0f0366-f7fa-4644-a41b-aa020f0599f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nodes 59110 num_edges 132414 num_attrs 37\n"
     ]
    }
   ],
   "source": [
    "num_edges = edge_index.shape[1]\n",
    "num_attrs = edge_attr.shape[1]\n",
    "num_nodes = np.max(edge_index.cpu().numpy()) + 1\n",
    "print('num_nodes', num_nodes, \"num_edges\", num_edges, \"num_attrs\", num_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3410df6a-3c13-41fa-8069-d84d3660915e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = torch.arange(0, num_edges).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3017a4b6-bc53-4040-a971-314a7a648ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = RecLinear(num_edges, num_nodes, num_attrs, NUM_FEATURES, HIDDEN_CHANNELS,\n",
    "                  NUM_EDGE_CLASSES, NUM_LAYERS, DROPOUT).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57639ff2-d3ef-451a-850c-0329db9db114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0ae33b43-bcc1-4be9-ac80-7e6d36178cc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5632 1408\n",
      "[0 1 2 3 5]\n",
      "1 5632 1408\n",
      "[0 3 4 5 6]\n",
      "2 5632 1408\n",
      "[0 1 2 3 4]\n",
      "3 5632 1408\n",
      "[0 1 2 3 4]\n",
      "4 5632 1408\n",
      "[1 2 4 6 7]\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    print(fold, len(train_ids), len(test_ids))\n",
    "    print(train_ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2a230b15-5c7f-4b4b-b033-8cc2dcceb2b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ids, test_ids = next(iter(kfold.split(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "98ad4f1b-4a83-4c78-b2c3-81def609d70a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7040"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3691174c-2669-40b2-97e6-ef84fedd7558",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5632, 1408)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ids), len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "84308b6f-18a7-41a6-8e8f-e18b0a61a4f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.reset_parameters()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "loss_f = torch.nn.CrossEntropyLoss(weight=city_class_weights, ignore_index=-1)\n",
    "loss_mse = torch.nn.MSELoss()\n",
    "\n",
    "min_loss = 10000\n",
    "\n",
    "# print(\"fold\", fold)\n",
    "train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d6a3bc3c-451a-405f-9f54-2efbfeb1ea38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.sampler.SubsetRandomSampler at 0x2ad1215f40d0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subsampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "01af2e53-ebeb-4364-ae25-6dcde561412b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecLinear(\n",
       "  (embed): Embedding(132414, 32)\n",
       "  (node_embed): Embedding(59110, 32)\n",
       "  (node_embed1): Embedding(59110, 4)\n",
       "  (time_embed): Embedding(96, 32)\n",
       "  (week_embed): Embedding(7, 32)\n",
       "  (node_lin): Linear(in_features=4, out_features=32, bias=True)\n",
       "  (node_lin1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (attr_lin): Linear(in_features=37, out_features=32, bias=True)\n",
       "  (attr_lin1): Sequential(\n",
       "    (0): Linear(in_features=37, out_features=32, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (lins): ModuleList(\n",
       "    (0): Linear(in_features=192, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=3, bias=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=59110, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=32, bias=True)\n",
       "  (fc4): Linear(in_features=32, out_features=256, bias=True)\n",
       "  (fc5): Linear(in_features=256, out_features=59110, bias=True)\n",
       "  (conv1): ModuleList(\n",
       "    (0-2): 3 x GATv2Conv(32, 32, heads=1)\n",
       "  )\n",
       "  (conv2): ModuleList(\n",
       "    (0-2): 3 x GATv2Conv(32, 32, heads=1)\n",
       "  )\n",
       "  (gcn_lin1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (gcn_lin2): Linear(in_features=64, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bc9c3d47-bb49-40bd-93b2-f76868ac4b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "67e6bdb4-60ef-4da9-b63a-2496fb014821",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 0/2816 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "pbar = tqdm.tqdm(\n",
    "    torch_geometric.loader.dataloader.DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                                                 num_workers=2, sampler=train_subsampler),\n",
    "    \"train\",\n",
    "    total=len(train_dataset) // BATCH_SIZE, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9fb7aa21-f57e-4cda-a2b5-1f1a51a82bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 0/2816 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[118220, 4], y=[264828], volume_class=[264828], median_speed=[264828], max_speed=[264828], t=[2], cluster=[2], week=[2], batch=[118220], ptr=[3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for data in pbar:\n",
    "    data = data.to(device)\n",
    "    data.x[data.x > 23.91] = 23.91\n",
    "    data.x[data.x == -1] = nan_to_num_map[CITY]\n",
    "    loss = 0.\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "78185639-90e9-48f9-b42a-70e3402d8175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[118220, 4], y=[264828], volume_class=[264828], median_speed=[264828], max_speed=[264828], t=[2], cluster=[2], week=[2], batch=[118220], ptr=[3])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b98c1e4a-e968-4602-8ea7-87544b30dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (count == 0):\n",
    "    lens = data.x.shape[0] // BATCH_SIZE\n",
    "    lens1 = data.y.shape[0] // BATCH_SIZE\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c0c80c6a-1688-4d06-a04c-43824ccd4cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59110, 132414)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens, lens1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e95629c5-2305-4cae-bb43-0c710c5de921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y.shape[0] // lens1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f1c45895-238a-40d9-97af-27a93d9311e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3751,  3751,  3751,  ..., 59107, 59108, 59109], device='cuda:0')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3685b2ff-b9b8-4173-8efc-a1549bbe1c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(55, device='cuda:0')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8be0e8f9-4049-42a2-b689-bbb7b37be1fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(54, device='cuda:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5955fbd8-1173-47a3-8fb2-87ba49ec93d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0, device='cuda:0'), tensor(0, device='cuda:0'))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.week[0], data.week[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fbcd7725-2a22-436d-a7ce-f88623a8916d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan, 1., 1.,  ..., 1., nan, nan], device='cuda:0')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "data.y[i * lens1:(i + 1) * lens1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "20003523-0d19-4cb2-800d-42bc81488e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.0721e-01,  2.1699e-01,  6.0077e-03, -1.4744e-02],\n",
       "        [ 1.0977e-01,  1.6165e-01,  1.3744e-01, -9.0963e-04],\n",
       "        [-3.9520e-01, -3.0873e-01, -3.6061e-01, -3.9174e-01],\n",
       "        ...,\n",
       "        [-1.2100e+00, -1.2100e+00, -1.2100e+00, -1.2100e+00],\n",
       "        [-1.2100e+00, -1.2100e+00, -1.2100e+00, -1.2100e+00],\n",
       "        [-1.2100e+00, -1.2100e+00, -1.2100e+00, -1.2100e+00]], device='cuda:0')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x[i * lens:(i + 1) * lens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "16c20d38-8793-4e58-be26-d064b874ac25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(data.y.shape[0] // lens1):\n",
    "    t = data.t[i]\n",
    "    cur_t = torch.ones_like(edge_index[0]) * t\n",
    "    week = data.week[i]\n",
    "    cur_week = torch.ones_like(edge_index[0]) * week\n",
    "\n",
    "    y = data.y[i * lens1:(i + 1) * lens1].nan_to_num(-1)\n",
    "    x = data.x[i * lens:(i + 1) * lens]\n",
    "    y_hat, x_rec = model(index, edge_index, x,\n",
    "                         edge_attr, cur_t, cur_week)\n",
    "    y = y.long()\n",
    "\n",
    "    train_index = torch.nonzero(torch.sum(x, dim=1) != nan_to_num_map[CITY] * 4).squeeze()\n",
    "\n",
    "    rec_loss = loss_mse(x[train_index], x_rec[train_index])\n",
    "    acc_loss = loss_f(y_hat, y)\n",
    "\n",
    "    loss += rec_loss + acc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f2e90c54-a1b1-4cc3-ac52-903716a1443f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3751,  3751,  3751,  ..., 59107, 59108, 59109],\n",
       "        [16812, 16813, 58530,  ..., 19129, 58304, 21202]], device='cuda:0')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9e004378-3ea9-43cd-a619-2ad153a57cdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0959,  0.2827,  0.2343,  0.1305],\n",
       "        [ 0.1236,  0.2032,  0.2447,  0.2204],\n",
       "        [-0.4021, -0.3572, -0.3087, -0.3053],\n",
       "        ...,\n",
       "        [-1.2100, -1.2100, -1.2100, -1.2100],\n",
       "        [-1.2100, -1.2100, -1.2100, -1.2100],\n",
       "        [-1.2100, -1.2100, -1.2100, -1.2100]], device='cuda:0')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1c089336-74f7-4f4b-a728-eef284f3cb9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4703, -0.4703, -0.9918,  ...,  0.0000,  1.0000,  0.0000],\n",
       "        [-0.4703, -0.4703, -0.9728,  ...,  0.0000,  1.0000,  0.0000],\n",
       "        [-0.4703, -0.4703, -0.9649,  ...,  0.0000,  0.0000,  1.0000],\n",
       "        ...,\n",
       "        [-0.4703, -0.4703, -0.9980,  ...,  0.0000,  0.0000,  1.0000],\n",
       "        [-0.6932, -0.6932, -0.9966,  ...,  0.0000,  0.0000,  1.0000],\n",
       "        [-0.4703, -0.4703, -0.9969,  ...,  0.0000,  0.0000,  1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6838c332-cb5e-43ee-8077-cfd928528dcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([132414, 37])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8e8699c-3213-4a1f-abf9-64b62b2a6ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([44, 44, 44,  ..., 44, 44, 44], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32fff507-0cce-4827-8fb8-e93759cec30e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4,  ..., 4, 4, 4], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f1ac4a3-c828-4b08-a9ae-968d3a25a661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0df72e9-ff40-43f2-a374-f8403c28870e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_idx = (torch.sum(x, dim=1, keepdim=True) != nan_to_num_map[CITY] * 4).type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b053758-3020-484c-b7c3-c58f867b1ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([59110, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x, dim=1, keepdim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4c5f5b28-5b9b-4b2f-a94e-f98e7993244d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xmax = 23.91\n",
    "xmin = nan_to_num_map[CITY]\n",
    "x_norm = (x - xmin) / (xmax - xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c1d0ca5d-69a4-4656-83f5-85b05af77950",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0316, 0.0378, 0.0411, 0.0389],\n",
       "        [0.0506, 0.0503, 0.0498, 0.0553],\n",
       "        [0.0439, 0.0400, 0.0436, 0.0423],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "13fd53bd-a03a-4934-b5a5-ef5d6324b5d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1627586468387787"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = 0.8 + 0.4 * np.random.rand(1)[0]\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14682dbb-741c-4e9d-9df8-2c784d0f2c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_norm = x_norm * ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "edf5442f-5d31-4f75-9f03-70ed40e3fe35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2663],\n",
       "        [0.5309],\n",
       "        [0.0177],\n",
       "        ...,\n",
       "        [0.0608],\n",
       "        [0.5850],\n",
       "        [0.8980]], device='cuda:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand_like(x_norm[:, 0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "49820a84-2b9c-4007-a810-df9b7d143150",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], device='cuda:0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_idx = (torch.rand_like(x_norm[:, 0:1]) > 0.4).type(torch.float)\n",
    "drop_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "32efd1f8-428b-4f84-b2c8-d4d1472b09e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_norm = x_norm * drop_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "726ae28b-0104-4ce7-885a-e0a202daa2e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([59110, 4])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1087f0a1-2bbe-4bfd-a4a9-ecbe6982aede",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 59110])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm = torch.transpose(x_norm, 0, 1)\n",
    "x_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c4a06430-21cd-4a2c-9596-2a9accfc2afa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mu, log_var = model.encode(x_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6c7f0159-e110-445b-8c71-06d4d3d56850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z = model.reparameterize(mu, log_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fa061873-f2f9-431f-9322-a09438cd69b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_rec = model.decode(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8ecbf24b-860f-490f-8eca-94a6ca627872",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0526,  0.0582,  0.0420,  ...,  0.1324, -1.0387, -0.1499],\n",
       "        [ 0.0536,  0.0569,  0.0414,  ...,  0.1187, -1.0274, -0.1508],\n",
       "        [ 0.0539,  0.0579,  0.0422,  ...,  0.1143, -1.0406, -0.1488],\n",
       "        [ 0.0537,  0.0576,  0.0421,  ...,  0.1118, -1.0372, -0.1484]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3f2e4deb-744e-4a3b-aa3f-d2347096d307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_rec = x_rec / ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8e704bdc-34e0-4dc6-a410-8145bfb2c6db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([59110, 4])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rec = torch.transpose(x_rec, 0, 1)\n",
    "x_rec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e07a2f8b-d578-44c4-bf25-ab3901661e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_rec = x_rec * (xmax - xmin) + xmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6ad00e04-dcd9-4731-8668-4c0957ba1e97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.3412e-02, -5.2531e-02, -4.5680e-02, -5.0454e-02],\n",
       "        [ 4.7557e-02,  1.9235e-02,  4.1158e-02,  3.4510e-02],\n",
       "        [-3.0330e-01, -3.1479e-01, -2.9906e-01, -3.0113e-01],\n",
       "        ...,\n",
       "        [ 1.6503e+00,  1.3539e+00,  1.2588e+00,  1.2051e+00],\n",
       "        [-2.3650e+01, -2.3406e+01, -2.3691e+01, -2.3618e+01],\n",
       "        [-4.4491e+00, -4.4678e+00, -4.4247e+00, -4.4170e+00]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2c839ed8-4bdd-4109-9bd0-73415fb05280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_rec1 = mask_idx * x + (1 - mask_idx) * x_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b5f6c4fd-cb10-4d1f-b2f8-623307b837ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.4160,  -0.2603,  -0.1773,  -0.2326],\n",
       "        [  0.0613,   0.0544,   0.0406,   0.1789],\n",
       "        [ -0.1081,  -0.2050,  -0.1150,  -0.1462],\n",
       "        ...,\n",
       "        [  1.6503,   1.3539,   1.2588,   1.2051],\n",
       "        [-23.6502, -23.4062, -23.6905, -23.6179],\n",
       "        [ -4.4491,  -4.4678,  -4.4247,  -4.4170]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc957824-3983-415f-91e2-8af52e866bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1, -1, -1,  ..., -1, -1, -1], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9337a33e-5d50-4b67-8398-79446c9cca24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1,  0,  1,  2], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1afb420a-ea7a-418f-9211-066da34e2c04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4160, -0.2603, -0.1773, -0.2326],\n",
       "        [ 0.0613,  0.0544,  0.0406,  0.1789],\n",
       "        [-0.1081, -0.2050, -0.1150, -0.1462],\n",
       "        ...,\n",
       "        [-1.2100, -1.2100, -1.2100, -1.2100],\n",
       "        [-1.2100, -1.2100, -1.2100, -1.2100],\n",
       "        [-1.2100, -1.2100, -1.2100, -1.2100]], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a0fe3f-b01a-4428-93b0-d50d74573dab",
   "metadata": {},
   "source": [
    "# Testing inference mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4351c757-4599-48f2-9a6f-68934a7d2099",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecLinear(\n",
       "  (embed): Embedding(132414, 32)\n",
       "  (node_embed): Embedding(59110, 32)\n",
       "  (node_embed1): Embedding(59110, 4)\n",
       "  (time_embed): Embedding(96, 32)\n",
       "  (week_embed): Embedding(7, 32)\n",
       "  (node_lin): Linear(in_features=4, out_features=32, bias=True)\n",
       "  (node_lin1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (attr_lin): Linear(in_features=39, out_features=32, bias=True)\n",
       "  (attr_lin1): Sequential(\n",
       "    (0): Linear(in_features=39, out_features=32, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (lins): ModuleList(\n",
       "    (0): Linear(in_features=192, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=3, bias=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=59110, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=32, bias=True)\n",
       "  (fc4): Linear(in_features=32, out_features=256, bias=True)\n",
       "  (fc5): Linear(in_features=256, out_features=59110, bias=True)\n",
       "  (conv1): ModuleList(\n",
       "    (0-2): 3 x GATv2Conv(32, 32, heads=1)\n",
       "  )\n",
       "  (conv2): ModuleList(\n",
       "    (0-2): 3 x GATv2Conv(32, 32, heads=1)\n",
       "  )\n",
       "  (gcn_lin1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (gcn_lin2): Linear(in_features=64, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "960526cc-5c4f-4409-aa4d-c5a839af0fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[59110, 4], t=44, cluster=0, week=4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "data = next(iter(test_dataset))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "100880b1-1632-4a88-a5a7-4486d5038717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2108897b-b407-4c6c-a913-4bfb9d0f66f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[290., 284., 313., 311.],\n",
       "        [415., 454., 440., 442.],\n",
       "        [282., 301., 291., 296.],\n",
       "        ...,\n",
       "        [ -1.,  -1.,  -1.,  -1.],\n",
       "        [ -1.,  -1.,  -1.,  -1.],\n",
       "        [ -1.,  -1.,  -1.,  -1.]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d62fb7bd-17ab-4304-9410-4ee59fb44990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[23.9100, 23.9100, 23.9100, 23.9100],\n",
       "        [23.9100, 23.9100, 23.9100, 23.9100],\n",
       "        [23.9100, 23.9100, 23.9100, 23.9100],\n",
       "        ...,\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-1.0000, -1.0000, -1.0000, -1.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x[data.x > 23.91] = 23.91\n",
    "data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "950db58e-b3c8-4047-a310-aa21476f9e39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[23.9100, 23.9100, 23.9100, 23.9100],\n",
       "        [23.9100, 23.9100, 23.9100, 23.9100],\n",
       "        [23.9100, 23.9100, 23.9100, 23.9100],\n",
       "        ...,\n",
       "        [-1.2100, -1.2100, -1.2100, -1.2100],\n",
       "        [-1.2100, -1.2100, -1.2100, -1.2100],\n",
       "        [-1.2100, -1.2100, -1.2100, -1.2100]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x[data.x == -1] = nan_to_num_map[CITY]\n",
    "data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ad2a7b0-0877-4ddd-ba10-304324879146",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = data.t\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a659a51-cd07-4d81-b78c-011a0dd055bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([44, 44, 44,  ..., 44, 44, 44], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_t = torch.ones_like(edge_index[0]) * t\n",
    "cur_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98d10c16-9540-48ee-bf3f-c827040a8667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week = data.week\n",
    "week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c0dbf28-12c7-49f8-8634-b395a4185f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cur_week = torch.ones_like(edge_index[0]) * week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98a1af1e-819b-479a-bc01-c1b56bc0ec5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/cc/class_L3_H32_F-1_Nzs_B2_e20/london_2/model_0_016.pt\n",
      "torch.Size([132414, 3]) tensor([[ 3.0692,  1.4098, -3.5911],\n",
      "        [ 3.8815,  2.5751, -5.1036],\n",
      "        [ 5.3915,  2.3949, -6.0946],\n",
      "        [ 3.8038,  0.7124, -3.5893],\n",
      "        [ 4.3619,  1.6560, -4.7951]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[ 2.6913,  1.1739, -3.0897],\n",
      "        [ 3.6341,  2.7222, -4.9575],\n",
      "        [ 5.9121,  2.6427, -6.6754],\n",
      "        [ 4.6326,  0.8336, -4.2185],\n",
      "        [ 4.5391,  1.8040, -5.0426]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[ 2.2826,  0.2595, -1.8338],\n",
      "        [ 4.0678,  2.4912, -5.0494],\n",
      "        [ 5.7483,  2.1528, -6.1262],\n",
      "        [ 5.5406,  1.3419, -5.2464],\n",
      "        [ 5.3434,  1.7030, -5.5393]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[ 3.2593,  1.7216, -4.0339],\n",
      "        [ 4.3313,  3.6788, -6.2417],\n",
      "        [ 6.7294,  3.5289, -8.0126],\n",
      "        [ 3.8311,  0.1867, -3.1252],\n",
      "        [ 3.6785,  1.7776, -4.3572]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[ 4.8888,  0.4068, -3.4604],\n",
      "        [ 7.4441,  3.7940, -8.0105],\n",
      "        [ 8.9097,  4.2098, -9.7044],\n",
      "        [ 7.0469,  1.0391, -5.9144],\n",
      "        [ 5.0304,  1.7202, -5.2157]], device='cuda:0')\n",
      "save/cc/class_L3_H32_F-1_Nzs_B2_e20/london_2/model_1_016.pt\n",
      "torch.Size([132414, 3]) tensor([[ -6.0389, -22.3874,  11.7590],\n",
      "        [ -1.1006, -15.2437,   4.3792],\n",
      "        [ -2.4338, -15.5813,   6.1913],\n",
      "        [ -0.5620,  -0.6137,  -0.0415],\n",
      "        [  5.9180,   0.6862,  -8.2688]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[  8.8412,  -0.5567, -12.3481],\n",
      "        [  9.5454,   1.5107, -13.1027],\n",
      "        [  5.4862,   0.5411,  -8.0144],\n",
      "        [  1.3946,  -0.4932,  -3.3548],\n",
      "        [  6.3189,   0.0439,  -8.0405]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[ -3.3488, -16.0273,   7.2420],\n",
      "        [ 10.2213,  -0.3523, -13.6387],\n",
      "        [  6.3734,   0.3154,  -8.6133],\n",
      "        [ -0.1511,  -1.2260,  -0.7106],\n",
      "        [  5.9685,   0.0611,  -7.1993]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[ -8.6339, -26.0846,  15.0821],\n",
      "        [  0.0643, -16.2347,   3.0691],\n",
      "        [ -1.5582, -17.0203,   5.1994],\n",
      "        [ -0.7400,  -0.2496,   0.3338],\n",
      "        [  4.7810,   0.1314,  -6.3830]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[ -2.8141, -13.9036,   5.1859],\n",
      "        [ 10.1318,  -2.9270, -12.7922],\n",
      "        [  5.8692,  -4.1900,  -6.4511],\n",
      "        [ -2.2658,   0.8669,   1.7739],\n",
      "        [  0.6433,   0.6067,  -2.7643]], device='cuda:0')\n",
      "save/cc/class_L3_H32_F-1_Nzs_B2_e20/london_2/model_2_016.pt\n",
      "torch.Size([132414, 3]) tensor([[ 13.5479,  -1.8836, -21.1713],\n",
      "        [  6.3972,   3.7968, -11.8674],\n",
      "        [  9.9058,   1.8881, -16.0734],\n",
      "        [  5.1591,  -1.9344,  -7.0303],\n",
      "        [  3.4495,   0.3047,  -5.2967]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[  8.8654,   1.3122, -14.3339],\n",
      "        [  2.5177,   1.0983,  -4.1978],\n",
      "        [  5.6747,   2.6803,  -9.1924],\n",
      "        [  6.0058,   0.9931,  -9.7049],\n",
      "        [  4.5364,   2.7969,  -7.4929]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[ 13.3857,  -0.1591, -20.9671],\n",
      "        [  3.0102,   0.5899,  -4.8174],\n",
      "        [ 10.6729,   3.0886, -16.9677],\n",
      "        [  5.5724,   0.5382,  -8.8300],\n",
      "        [  2.9425,   0.5273,  -4.5459]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[  9.5885,   0.8625, -15.2954],\n",
      "        [  1.6766,   0.3585,  -2.7505],\n",
      "        [  6.9156,   3.5688, -11.2376],\n",
      "        [  6.3006,   2.0842, -10.2454],\n",
      "        [  3.1800,   1.6840,  -5.2356]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[ 11.7003,   0.8364, -18.7640],\n",
      "        [  4.4231,   2.6395,  -7.3936],\n",
      "        [  5.9860,   1.0439,  -9.3114],\n",
      "        [  7.7006,   0.9608, -12.3500],\n",
      "        [  5.4826,   2.2036,  -8.8979]], device='cuda:0')\n",
      "save/cc/class_L3_H32_F-1_Nzs_B2_e20/london_2/model_3_016.pt\n",
      "torch.Size([132414, 3]) tensor([[-3.5653, -0.1158,  4.1628],\n",
      "        [-3.8042,  0.2685,  3.7825],\n",
      "        [-2.1331,  0.0174,  1.8881],\n",
      "        [-4.3772, -0.1644,  4.4409],\n",
      "        [-3.1083, -0.3209,  3.4115]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[-3.7310, -0.1578,  3.3362],\n",
      "        [-4.0384,  0.1416,  2.7393],\n",
      "        [-1.5386,  0.1781,  0.7149],\n",
      "        [-4.0380, -0.2399,  5.6717],\n",
      "        [-4.1988, -0.2462,  4.4873]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[-5.4653,  0.0713,  4.3987],\n",
      "        [-5.9696,  0.5467,  3.7471],\n",
      "        [-2.9812,  0.3922,  1.6793],\n",
      "        [-4.7549, -0.1820,  5.1062],\n",
      "        [-3.6785, -0.3154,  4.0337]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[-3.6520, -0.2390,  6.7423],\n",
      "        [-3.7136,  0.4645,  6.4373],\n",
      "        [-2.7515,  0.3565,  5.0996],\n",
      "        [-4.1531, -0.1693,  4.2279],\n",
      "        [-3.1122, -0.4258,  3.8457]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[-4.7143, -0.1835,  6.9188],\n",
      "        [-4.9725,  0.3201,  7.3912],\n",
      "        [-3.5742,  0.2271,  4.7477],\n",
      "        [-4.8179, -0.1104,  4.4993],\n",
      "        [-5.8493, -0.5617,  6.3034]], device='cuda:0')\n",
      "save/cc/class_L3_H32_F-1_Nzs_B2_e20/london_2/model_4_016.pt\n",
      "torch.Size([132414, 3]) tensor([[ 7.2893, -0.9128, -9.6488],\n",
      "        [ 1.1199, -0.5019, -0.6451],\n",
      "        [ 5.5906, -0.7675, -6.5414],\n",
      "        [-1.1474, -0.1244,  2.8930],\n",
      "        [-2.8161, -0.4196,  6.8454]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[  9.9210,  -0.4153, -16.3837],\n",
      "        [  3.0462,  -0.5389,  -4.8299],\n",
      "        [  5.2539,  -0.6448,  -7.6012],\n",
      "        [ -1.4522,   0.0582,   4.4280],\n",
      "        [ -2.9312,  -0.4721,   7.2972]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[ 11.6581,  -2.0955, -13.7144],\n",
      "        [  5.5964,  -1.8291,  -4.9201],\n",
      "        [  8.0910,  -2.0705,  -6.9864],\n",
      "        [ -1.7658,   0.1567,   5.0668],\n",
      "        [ -3.4063,  -0.0350,   6.1165]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[  9.3708,  -0.3477, -15.3044],\n",
      "        [  4.0987,  -0.2607,  -6.2670],\n",
      "        [  5.9254,  -0.7802,  -8.3988],\n",
      "        [ -1.3770,   0.0289,   3.9131],\n",
      "        [ -2.6628,  -0.4361,   6.7383]], device='cuda:0')\n",
      "torch.Size([132414, 3]) tensor([[  6.7978,  -0.2956, -11.0546],\n",
      "        [  2.4801,  -0.3411,  -4.3908],\n",
      "        [  4.1040,  -0.0459,  -6.2410],\n",
      "        [  0.8967,   0.0176,  -0.9921],\n",
      "        [ -2.9037,  -0.5521,   7.4700]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "save_path = \"save/cc/class_L3_H32_F-1_Nzs_B2_e20/london_2/\"\n",
    "y_pred = 0.\n",
    "for fold in range(5):\n",
    "    for mm in range(16, 21):\n",
    "        print(f\"{save_path}model_{fold}_{mm:03d}.pt\")\n",
    "        model.load_state_dict(torch.load(f\"{save_path}model_{fold}_{mm:03d}.pt\", map_location='cuda:0'))\n",
    "        model.eval()\n",
    "        for ii in range(5):\n",
    "            y_hat, _ = model(index, edge_index, data.x, edge_attr, cur_t, cur_week)\n",
    "            y_hat = y_hat.detach()\n",
    "            print(y_hat.shape, y_hat[:5])\n",
    "            y_pred += y_hat\n",
    "        break\n",
    "y_pred /= 125."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a09b12e-c6b3-42db-854f-482b3be30376",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  6.2839,  -0.3915,  -8.4779],\n",
       "        [  5.2118,   1.4126,  -7.4263],\n",
       "        [  5.9455,   1.2316,  -7.8422],\n",
       "        ...,\n",
       "        [ -2.2475,   1.5776,   2.1567],\n",
       "        [ 13.5077,   7.2808, -19.1663],\n",
       "        [  5.2458,   1.9448,  -7.3630]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d87d15b-5d29-4050-8576-d4a76e454658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = test_dataset.torch_road_graph_mapping._torch_to_df_cc(data=y_pred, day=\"test\", t=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd89c886-0e8c-4786-8e2c-033e8b737d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logit_green</th>\n",
       "      <th>logit_yellow</th>\n",
       "      <th>logit_red</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>day</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.283916</td>\n",
       "      <td>-0.391485</td>\n",
       "      <td>-8.477943</td>\n",
       "      <td>78112</td>\n",
       "      <td>25508583</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.211779</td>\n",
       "      <td>1.412575</td>\n",
       "      <td>-7.426338</td>\n",
       "      <td>78112</td>\n",
       "      <td>25508584</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.945462</td>\n",
       "      <td>1.231592</td>\n",
       "      <td>-7.842179</td>\n",
       "      <td>78112</td>\n",
       "      <td>3257621681005534125</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.780440</td>\n",
       "      <td>0.607034</td>\n",
       "      <td>-2.405866</td>\n",
       "      <td>99936</td>\n",
       "      <td>2146383887</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.419122</td>\n",
       "      <td>0.663258</td>\n",
       "      <td>-1.920764</td>\n",
       "      <td>99936</td>\n",
       "      <td>4544836433</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   logit_green  logit_yellow  logit_red      u                    v   day  t\n",
       "0     6.283916     -0.391485  -8.477943  78112             25508583  test  0\n",
       "1     5.211779      1.412575  -7.426338  78112             25508584  test  0\n",
       "2     5.945462      1.231592  -7.842179  78112  3257621681005534125  test  0\n",
       "3     1.780440      0.607034  -2.405866  99936           2146383887  test  0\n",
       "4     1.419122      0.663258  -1.920764  99936           4544836433  test  0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7151c6c2-3ca8-467c-90e1-cd65b8f1b3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for idx, data in tqdm.tqdm(enumerate(test_dataset), total=len(test_dataset)):\n",
    "    data = data.to(device)\n",
    "    data.x[data.x > 23.91] = 23.91\n",
    "    data.x[data.x == -1] = nan_to_num_map[opt['city']]\n",
    "\n",
    "    t = data.t\n",
    "    cur_t = torch.ones_like(edge_index[0]) * t\n",
    "    week = data.week\n",
    "    cur_week = torch.ones_like(edge_index[0]) * week\n",
    "\n",
    "    if (opt['city'] == 'melbourne'):\n",
    "        y_pred = 0.\n",
    "        for fold in range(5):\n",
    "            model.load_state_dict(torch.load(f\"{opt['save_path']}model_best_{fold}.pt\", map_location='cuda:0'))\n",
    "            model.eval()\n",
    "            for ii in range(5):\n",
    "                y_hat, _ = model(index, edge_index, data.x, edge_attr, cur_t, cur_week)\n",
    "                y_hat = y_hat.detach()\n",
    "                y_pred += y_hat\n",
    "        y_pred /= 25.\n",
    "    else:\n",
    "        y_pred = 0.\n",
    "        for fold in range(5):\n",
    "            for mm in range(16, 21):\n",
    "                model.load_state_dict(torch.load(f\"{opt['save_path']}model_{fold}_{mm:03d}.pt\", map_location='cuda:0'))\n",
    "                model.eval()\n",
    "                for ii in range(5):\n",
    "                    y_hat, _ = model(index, edge_index, data.x, edge_attr, cur_t, cur_week)\n",
    "                    y_hat = y_hat.detach()\n",
    "                    y_pred += y_hat\n",
    "        y_pred /= 125.\n",
    "\n",
    "    df = test_dataset.torch_road_graph_mapping._torch_to_df_cc(data=y_pred, day=\"test\", t=idx)\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df[\"test_idx\"] = df[\"t\"]\n",
    "del df[\"day\"]\n",
    "del df[\"t\"]\n",
    "\n",
    "submission = df\n",
    "# print(submission.head(20))\n",
    "\n",
    "# (BASEDIR / \"submissions\" / opt['submission_name'] / opt['city'] / \"labels\").mkdir(exist_ok=True, parents=True)\n",
    "# table = pa.Table.from_pandas(submission)\n",
    "# pq.write_table(table, BASEDIR / \"submissions\" / opt['submission_name'] / opt[\n",
    "#     'city'] / \"labels\" / f\"cc_labels_test.parquet\", compression=\"snappy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce312ac7-7aba-498d-bcf4-ccc1a34b9805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logit_green</th>\n",
       "      <th>logit_yellow</th>\n",
       "      <th>logit_red</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>day</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.283916</td>\n",
       "      <td>-0.391485</td>\n",
       "      <td>-8.477943</td>\n",
       "      <td>78112</td>\n",
       "      <td>25508583</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.211779</td>\n",
       "      <td>1.412575</td>\n",
       "      <td>-7.426338</td>\n",
       "      <td>78112</td>\n",
       "      <td>25508584</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.945462</td>\n",
       "      <td>1.231592</td>\n",
       "      <td>-7.842179</td>\n",
       "      <td>78112</td>\n",
       "      <td>3257621681005534125</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.780440</td>\n",
       "      <td>0.607034</td>\n",
       "      <td>-2.405866</td>\n",
       "      <td>99936</td>\n",
       "      <td>2146383887</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.419122</td>\n",
       "      <td>0.663258</td>\n",
       "      <td>-1.920764</td>\n",
       "      <td>99936</td>\n",
       "      <td>4544836433</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132409</th>\n",
       "      <td>-0.218619</td>\n",
       "      <td>1.644511</td>\n",
       "      <td>-0.039306</td>\n",
       "      <td>4595139612105786518</td>\n",
       "      <td>8842311879</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132410</th>\n",
       "      <td>2.548334</td>\n",
       "      <td>0.911821</td>\n",
       "      <td>-2.964944</td>\n",
       "      <td>8230831116681660864</td>\n",
       "      <td>1149426165</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132411</th>\n",
       "      <td>-2.247471</td>\n",
       "      <td>1.577633</td>\n",
       "      <td>2.156674</td>\n",
       "      <td>1688447984145568529</td>\n",
       "      <td>26559620</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132412</th>\n",
       "      <td>13.507724</td>\n",
       "      <td>7.280828</td>\n",
       "      <td>-19.166265</td>\n",
       "      <td>3771856370570656347</td>\n",
       "      <td>9402106041</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132413</th>\n",
       "      <td>5.245783</td>\n",
       "      <td>1.944845</td>\n",
       "      <td>-7.363039</td>\n",
       "      <td>4890701424133264627</td>\n",
       "      <td>27596189</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132414 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        logit_green  logit_yellow  logit_red                    u  \\\n",
       "0          6.283916     -0.391485  -8.477943                78112   \n",
       "1          5.211779      1.412575  -7.426338                78112   \n",
       "2          5.945462      1.231592  -7.842179                78112   \n",
       "3          1.780440      0.607034  -2.405866                99936   \n",
       "4          1.419122      0.663258  -1.920764                99936   \n",
       "...             ...           ...        ...                  ...   \n",
       "132409    -0.218619      1.644511  -0.039306  4595139612105786518   \n",
       "132410     2.548334      0.911821  -2.964944  8230831116681660864   \n",
       "132411    -2.247471      1.577633   2.156674  1688447984145568529   \n",
       "132412    13.507724      7.280828 -19.166265  3771856370570656347   \n",
       "132413     5.245783      1.944845  -7.363039  4890701424133264627   \n",
       "\n",
       "                          v   day  t  \n",
       "0                  25508583  test  0  \n",
       "1                  25508584  test  0  \n",
       "2       3257621681005534125  test  0  \n",
       "3                2146383887  test  0  \n",
       "4                4544836433  test  0  \n",
       "...                     ...   ... ..  \n",
       "132409           8842311879  test  0  \n",
       "132410           1149426165  test  0  \n",
       "132411             26559620  test  0  \n",
       "132412           9402106041  test  0  \n",
       "132413             27596189  test  0  \n",
       "\n",
       "[132414 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c339e7f-8b53-423d-bc7f-cafe667a9908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t4c22",
   "language": "python",
   "name": "t4c22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
