{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4130c0bf-20e4-42de-a787-ef3594f081a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51971c3a-1391-4b4b-ad17-fb9d0e7d7b67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015de87-b1ba-4dc7-aa00-b921466042de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693f55b-1edb-48db-b9ca-4917897e8a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GATv2Conv as GCNConv\n",
    "from torch_geometric_temporal.nn.recurrent import A3TGCN\n",
    "\n",
    "import t4c22\n",
    "from t4c22.metric.masked_crossentropy import get_weights_from_class_fractions\n",
    "from t4c22.t4c22_config import class_fractions\n",
    "from t4c22.t4c22_config import load_basedir\n",
    "from t4c22.dataloading.t4c22_dataset_geometric import T4c22GeometricDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1847cc-84b0-49c1-a5a8-ed7df8e4ccea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASEDIR = load_basedir(fn=\"t4c22_config.json\", pkg=t4c22)\n",
    "CITY = \"london\"\n",
    "IN_CHANNELS = 4\n",
    "HIDDEN_CHANNELS = 32\n",
    "OUT_CHANNELS = 3\n",
    "PERIODS = 1\n",
    "NUM_LAYERS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8f88be-7354-4320-b698-4c7636b567ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "device = torch.device(\"cuda\", 0) if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255bd4d2-7059-47c4-80e8-6c3a5a6a6c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = T4c22GeometricDataset(root=BASEDIR, city=CITY,\n",
    "                                edge_attributes=[\"speed_kph\", \"parsed_maxspeed\", \"length_meters\", \"counter_distance\",\n",
    "                                                 \"importance\", \"highway\", \"oneway\", ], split=\"train\", fill=1,\n",
    "                                normalize=\"zs\", cachedir=Path(f\"{BASEDIR}/cache\"), idx=0)\n",
    "print(\"################## Data Information #################\")\n",
    "print(\"Dataset Size\\t\", len(dataset))\n",
    "print(\"The statistics of training set are: Min [%d]\\tMax [%d]\\tMean [%.4f]\\tStd[%.4f]\" % (\n",
    "    dataset.min_volume, dataset.max_volume, dataset.mean_volume, dataset.std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2f6168-6d64-4937-be07-fd33ba098795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spl = int(((0.8 * len(dataset)) // 2) * 2)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [spl, len(dataset) - spl])\n",
    "print(\"Train Dataset Size\\t\", len(train_dataset))\n",
    "print(\"Validation Dataset Size\\t\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f58e2-8287-49b0-bbac-6320ca0d0dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "city_class_fractions = class_fractions[CITY]\n",
    "city_class_weights = torch.tensor(\n",
    "    get_weights_from_class_fractions(\n",
    "        [city_class_fractions['green'], city_class_fractions['yellow'],\n",
    "         city_class_fractions['red']])).float()\n",
    "print(\"City Class Weight\\t\", city_class_weights)\n",
    "print(\"######################## End ########################\")\n",
    "\n",
    "nan_to_num_map = {\"london\": -1.21, \"melbourne\": -0.8, \"madrid\": -0.56}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3ed882-938e-4eb5-a544-75c448c6938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGNN(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, hidden_channels, dim_in, periods, out_channels):\n",
    "        super().__init__()\n",
    "        self.gcn_lin1 = nn.Linear(dim_in * 2, dim_in)\n",
    "        self.tgnn = A3TGCN(in_channels=dim_in, out_channels=hidden_channels, periods=periods)\n",
    "        self.out_linear = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x_i = torch.index_select(x, 0, edge_index[0])\n",
    "        x_j = torch.index_select(x, 0, edge_index[1])\n",
    "        x = torch.concat([x_i, x_j], dim=1)\n",
    "        x = self.gcn_lin1(x)\n",
    "        h = self.tgnn(x.unsqueeze(2), edge_index).relu()\n",
    "        h = self.out_linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeb7a1f-e4a5-4e24-9a84-9d5341a325fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "city_class_weights = city_class_weights.to(device)\n",
    "edge_index = dataset.edge_index.to(device)\n",
    "edge_attr = dataset.edge_attr.to(device)\n",
    "\n",
    "num_edges = edge_index.shape[1]\n",
    "num_attrs = edge_attr.shape[1]\n",
    "num_nodes = np.max(edge_index.cpu().numpy()) + 1\n",
    "print('num_nodes', num_nodes)\n",
    "\n",
    "index = torch.arange(0, num_edges).to(device)\n",
    "\n",
    "# if not os.path.exists(opt['save_path']):\n",
    "#     os.makedirs(opt['save_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bb709-d3d0-4c50-8151-d2b3ed7d2136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9400e56-b8eb-4c76-b150-0fa1bc1442ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(train_dataset.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0188c75c-8109-4789-99cb-944341dea588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset.dataset.get(0).x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461a2a03-135c-46c7-be14-593f612beef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset.dataset.get(0).y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d44bbc-235c-434f-9998-2a86b0ac2bd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset.dataset.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248fe82-00a1-44d9-a56e-430cc90221b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset.dataset.edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb1e47-e433-474a-a6f2-7bcd2eac6425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset.dataset.edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4e5096-6d73-48a3-8806-07125140edcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset.dataset.edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgnn = TemporalGNN(num_nodes, 32, 4, 1, 3)\n",
    "optimizer = torch.optim.AdamW(tgnn.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "loss_f = torch.nn.CrossEntropyLoss(weight=city_class_weights, ignore_index=-1)\n",
    "loss_mse = torch.nn.MSELoss()\n",
    "tgnn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea781d40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b0352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ids, test_ids = next(iter(kfold.split(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be2702d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaedae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1cb9f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "pbar = tqdm.tqdm(\n",
    "    torch_geometric.loader.dataloader.DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                                                 num_workers=8, sampler=train_subsampler),\n",
    "    \"train\",\n",
    "    total=len(train_dataset) // BATCH_SIZE, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8611f89a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for data in pbar:\n",
    "    data = data.to(device)\n",
    "    data.x[data.x > 23.91] = 23.91\n",
    "    data.x[data.x == -1] = nan_to_num_map[CITY]\n",
    "    loss = 0.\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b8e71f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = 0.\n",
    "if (count == 0):\n",
    "    lens = data.x.shape[0] // BATCH_SIZE\n",
    "    lens1 = data.y.shape[0] // BATCH_SIZE\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de5a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.y.shape[0] // lens1):\n",
    "    y = data.y[i * lens1:(i + 1) * lens1].nan_to_num(-1)\n",
    "    x = data.x[i * lens:(i + 1) * lens]\n",
    "    y_hat = tgnn(x, edge_index, edge_attr)\n",
    "    y = y.long()\n",
    "\n",
    "    train_index = torch.nonzero(torch.sum(x, dim=1) != nan_to_num_map[CITY] * 4).squeeze()\n",
    "\n",
    "    loss += loss_f(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2fe4b2",
   "metadata": {},
   "source": [
    "# Replacing three GAT layers with one A3TGCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a97526c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Traffic4castA3TGCN(nn.Module):\n",
    "    def __init__(self, num_edges, num_nodes, num_attrs, in_channels, hidden_channels, out_channels, num_layers, periods):\n",
    "\n",
    "        super(Traffic4castA3TGCN, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(num_edges, hidden_channels)\n",
    "        self.node_embed = nn.Embedding(num_nodes, hidden_channels)\n",
    "        self.node_embed1 = nn.Embedding(num_nodes, 4)\n",
    "        self.time_embed = nn.Embedding(96, hidden_channels)\n",
    "        self.week_embed = nn.Embedding(7, hidden_channels)\n",
    "        self.node_index = torch.arange(0, num_nodes).to(device)\n",
    "\n",
    "        self.node_lin = nn.Linear(in_channels, hidden_channels)\n",
    "        self.node_lin1 = nn.Linear(hidden_channels * 2, hidden_channels)\n",
    "        self.attr_lin = nn.Linear(num_attrs, hidden_channels)\n",
    "        self.attr_lin1 = nn.Sequential(nn.Linear(num_attrs, hidden_channels), nn.LeakyReLU(),\n",
    "                                       nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels * 6, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.fc1 = nn.Linear(num_nodes, 256)\n",
    "        self.fc2 = nn.Linear(256, 32)  # mean vector\n",
    "        self.fc3 = nn.Linear(256, 32)  # standard deviation vector\n",
    "        self.fc4 = nn.Linear(32, 256)\n",
    "        self.fc5 = nn.Linear(256, num_nodes)\n",
    "\n",
    "        self.tgnn = A3TGCN(in_channels=in_channels, out_channels=hidden_channels, periods=periods)\n",
    "\n",
    "        self.conv1 = torch.nn.ModuleList()\n",
    "        for i in range(3):\n",
    "            self.conv1.append(GCNConv(hidden_channels, hidden_channels, edge_dim=hidden_channels))\n",
    "\n",
    "        self.conv2 = torch.nn.ModuleList()\n",
    "        for i in range(3):\n",
    "            self.conv2.append(GCNConv(hidden_channels, hidden_channels, edge_dim=hidden_channels))\n",
    "\n",
    "        self.gcn_lin1 = nn.Linear(in_channels * 2, in_channels)\n",
    "        self.gcn_lin2 = nn.Linear(hidden_channels * 2, hidden_channels)\n",
    "\n",
    "    def gelu(self, x):\n",
    "        return 0.5 * x * (1 + F.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.gelu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"Gaussian sampling\"\"\"\n",
    "        std = torch.exp(log_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.gelu(self.fc4(z))\n",
    "        h = self.fc5(h)\n",
    "        return h\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.embed.reset_parameters()\n",
    "        self.node_embed.reset_parameters()\n",
    "        self.node_embed1.reset_parameters()\n",
    "        self.time_embed.reset_parameters()\n",
    "        self.node_lin.reset_parameters()\n",
    "        self.node_lin1.reset_parameters()\n",
    "        self.attr_lin.reset_parameters()\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()\n",
    "        self.fc3.reset_parameters()\n",
    "        self.fc4.reset_parameters()\n",
    "        self.fc5.reset_parameters()\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        for lin in self.conv1:\n",
    "            lin.reset_parameters()\n",
    "        for lin in self.conv2:\n",
    "            lin.reset_parameters()\n",
    "        self.gcn_lin1.reset_parameters()\n",
    "        self.gcn_lin2.reset_parameters()\n",
    "\n",
    "    def forward(self, index, edge_index, x, attr, cur_t, cur_w):\n",
    "        mask_idx = (torch.sum(x, dim=1, keepdim=True) != nan_to_num_map[CITY] * 4).type(torch.float)\n",
    "\n",
    "        xmax = 23.91\n",
    "        xmin = nan_to_num_map[CITY]\n",
    "        x_norm = (x - xmin) / (xmax - xmin)\n",
    "\n",
    "        ratio = 0.8 + 0.4 * np.random.rand(1)[0]\n",
    "\n",
    "        x_norm = x_norm * ratio\n",
    "\n",
    "        drop_idx = (torch.rand_like(x_norm[:, 0:1]) > 0.4).type(torch.float)\n",
    "        x_norm = x_norm * drop_idx\n",
    "\n",
    "        x_norm = torch.transpose(x_norm, 0, 1)\n",
    "        mu, log_var = self.encode(x_norm)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_rec = self.decode(z)\n",
    "\n",
    "        x_rec = x_rec / ratio\n",
    "\n",
    "        x_rec = torch.transpose(x_rec, 0, 1)\n",
    "        x_rec = x_rec * (xmax - xmin) + xmin\n",
    "        x_rec1 = mask_idx * x + (1 - mask_idx) * x_rec\n",
    "\n",
    "        attr1 = self.attr_lin(attr)\n",
    "        embed = self.embed(index)\n",
    "\n",
    "        node_embed = self.node_embed(self.node_index)\n",
    "        pre_data = node_embed\n",
    "        for conv in self.conv1:\n",
    "            node_embed = conv(node_embed, edge_index, attr1)\n",
    "            node_embed = self.gelu(node_embed) + pre_data\n",
    "\n",
    "        data = x_rec1\n",
    "        x_i = torch.index_select(data, 0, edge_index[0])\n",
    "        x_j = torch.index_select(data, 0, edge_index[1])\n",
    "        x = torch.concat([x_i, x_j], dim=1)\n",
    "        x = self.gcn_lin1(x)\n",
    "\n",
    "        # Instead of just GCN apply A3TGCN\n",
    "        x = self.tgnn(x.unsqueeze(2), edge_index).relu()\n",
    "\n",
    "        x_i = torch.index_select(node_embed, 0, edge_index[0])\n",
    "        x_j = torch.index_select(node_embed, 0, edge_index[1])\n",
    "        x1 = torch.concat([x_i, x_j], dim=1)\n",
    "        x1 = self.gcn_lin2(x1)\n",
    "\n",
    "        time_embed = self.time_embed(cur_t.long())\n",
    "        week_embed = self.week_embed(cur_w.long())\n",
    "\n",
    "        xf = torch.cat([embed, self.attr_lin1(attr), x, x1, time_embed, week_embed], dim=1)\n",
    "\n",
    "        for lin in self.lins[:-1]:\n",
    "            xf = lin(xf)\n",
    "            xf = self.gelu(xf)\n",
    "\n",
    "        xf = self.lins[-1](xf)\n",
    "\n",
    "        return xf, x_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50269854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tgnn = Traffic4castA3TGCN(num_edges, num_nodes, num_attrs, IN_CHANNELS, HIDDEN_CHANNELS, OUT_CHANNELS, NUM_LAYERS, PERIODS).to(device)\n",
    "optimizer = torch.optim.AdamW(tgnn.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "loss_f = torch.nn.CrossEntropyLoss(weight=city_class_weights, ignore_index=-1)\n",
    "loss_mse = torch.nn.MSELoss()\n",
    "tgnn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e5754c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(data.y.shape[0] // lens1):\n",
    "    t = data.t[i]\n",
    "    cur_t = torch.ones_like(edge_index[0]) * t\n",
    "    week = data.week[i]\n",
    "    cur_week = torch.ones_like(edge_index[0]) * week\n",
    "\n",
    "    y = data.y[i * lens1:(i + 1) * lens1].nan_to_num(-1)\n",
    "    x = data.x[i * lens:(i + 1) * lens]\n",
    "    y_hat, x_rec = tgnn(index, edge_index, x,\n",
    "                         edge_attr, cur_t, cur_week)\n",
    "    y = y.long()\n",
    "\n",
    "    train_index = torch.nonzero(torch.sum(x, dim=1) != nan_to_num_map[CITY] * 4).squeeze()\n",
    "\n",
    "    rec_loss = loss_mse(x[train_index], x_rec[train_index])\n",
    "    acc_loss = loss_f(y_hat, y)\n",
    "\n",
    "    loss += rec_loss + acc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5d00e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t4c22_pygt",
   "language": "python",
   "name": "t4c22_pygt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
